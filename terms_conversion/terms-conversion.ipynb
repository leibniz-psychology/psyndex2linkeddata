{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting PSYNDEX Terms Vocabulary to SKOS\n",
    "\n",
    "\n",
    "Import libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Literal\n",
    "from rdflib.namespace import RDF, RDFS, Namespace, SKOS, XSD\n",
    "from rdflib import BNode\n",
    "from rdflib import URIRef\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "\n",
    "BF = Namespace(\"http://id.loc.gov/ontologies/bibframe/\")\n",
    "BFLC = Namespace(\"http://id.loc.gov/ontologies/bflc/\")\n",
    "MADS = Namespace(\"http://www.loc.gov/mads/rdf/v1#\")\n",
    "SCHEMA = Namespace(\"https://schema.org/\")\n",
    "WORKS = Namespace(\"https://w3id.org/zpid/resources/works/\")\n",
    "INSTANCES = Namespace(\"https://w3id.org/zpid/resources/instances/\")\n",
    "PXC = Namespace(\"https://w3id.org/zpid/ontology/classes/\")\n",
    "PXP = Namespace(\"https://w3id.org/zpid/ontology/properties/\")\n",
    "LANG = Namespace (\"http://id.loc.gov/vocabulary/iso639-2/\")\n",
    "LOCID = Namespace(\"http://id.loc.gov/vocabulary/identifiers/\")\n",
    "ROLES = Namespace(\"https://w3id.org/zpid/vocabs/roles/\")\n",
    "\n",
    "TERMS = Namespace(\"https://w3id.org/zpid/vocabs/terms/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# make a list/set of newly added terms (postables = new concepts and nonpostables = new synoyms)\n",
    "\"# this update:\",\n",
    "\n",
    "# new postables:\n",
    "new_concepts = {\"Algorithmic Bias\",\n",
    "\"Artificial Intelligence Ethics\",\n",
    "\"Automated Diagnosis\",\n",
    "\"Bayesian Algorithms\",\n",
    "\"Brain Computer Interface\",\n",
    "\"Breathing Techniques\",\n",
    "\"Chatbots\",\n",
    "\"Classification (Machine Learning)\",\n",
    "\"Clustering (Machine Learning)\",\n",
    "\"Cognitive Analytic Therapy\",\n",
    "\"Compassion Focused Therapy\",\n",
    "\"Computer Assisted Surgery\",\n",
    "\"Computer Graphics\",\n",
    "\"Computer Linguistics\",\n",
    "\"Computer Security\",\n",
    "\"Computer Systems\",\n",
    "\"Computer Vision\",\n",
    "\"Confirmation Bias\",\n",
    "\"Conversation Analysis\",\n",
    "\"Convolutional Neural Networks\",\n",
    "\"Cortical Excitability\",\n",
    "\"Decision Tree Algorithms \",\n",
    "\"Dietary Treatment\",\n",
    "\"Digital Audio\",\n",
    "\"Digital Piracy\",\n",
    "\"Emotion Detection (Artificial Intelligence)\",\n",
    "\"Equine Assisted Therapy\",\n",
    "\"Ethical Decision Making\",\n",
    "\"Exercise Therapy\",\n",
    "\"Exposure and Response Prevention Therapy\",\n",
    "\"Facial Recognition (Artificial Intelligence)\",\n",
    "\"Generative Adversarial Networks \",\n",
    "\"Generative Artificial Intelligence\",\n",
    "\"Humanoid Robots\",\n",
    "\"Image Classification\",\n",
    "\"Intelligent Personal Agents\",\n",
    "\"Internet Access\",\n",
    "\"Large Language Models\",\n",
    "\"Machine Translation\",\n",
    "\"Mentalization-Based Interventions\",\n",
    "\"Metacognitive Therapy\",\n",
    "\"Mindfulness Meditation\",\n",
    "\"Mindfulness-Based Cognitive Therapy \",\n",
    "\"Mindfulness-Based Stress Reduction \",\n",
    "\"Moral Emotions\",\n",
    "\"Nature-Based Interventions\",\n",
    "\"Neuroethics\",\n",
    "\"Noninvasive Brain Stimulation \",\n",
    "\"Optimization Algorithms\",\n",
    "\"Oxygen Therapy\",\n",
    "\"Podcasts\",\n",
    "\"Positive Behavior Support\",\n",
    "\"Positive Psychology Therapy\",\n",
    "\"Post-COVID-19 Conditions\",\n",
    "\"Predictive Analysis\",\n",
    "\"Protective Behavioral Strategies\",\n",
    "\"Psychosocial Interventions\",\n",
    "\"Publication Bias\",\n",
    "\"Recommender Systems\",\n",
    "\"Recurrent Neural Networks\",\n",
    "\"Regression (Machine Learning)\",\n",
    "\"Repetitive Transcranial Brain Stimulation\",\n",
    "\"Research Bias\",\n",
    "\"Research Inclusivity\",\n",
    "\"Robot Ethics\",\n",
    "\"Sensor Technology\",\n",
    "\"Social Prescribing\",\n",
    "\"Socially Assistive Robots\",\n",
    "\"Spiking Neural Networks\",\n",
    "\"Spiritually Oriented Therapy\",\n",
    "\"Supervised Learning\",\n",
    "\"Support Vector Machine Algorithms\",\n",
    "\"Theta Burst Stimulation\",\n",
    "\"Thought Patterns\",\n",
    "\"Transcranial Alternating Current Stimulation\",\n",
    "\"Trauma-Focused Cognitive Behavior Therapy\"}\n",
    "\n",
    "# new \"nonpostables\"\n",
    "new_altlabels = { \n",
    "\"Aversion Therapy\",\n",
    "\"Brain Computer Interface\",\n",
    "\"Cloud Computing\",\n",
    "\"Compassion Focused Therapy\",\n",
    "\"Computer Linguistics\",\n",
    "\"Computer Systems\",\n",
    "\"Synthetic Speech\",\n",
    "\"Text Analysis\",\n",
    "\"Culturally Adapted Interventions\",\n",
    "\"Computer Security\",\n",
    "\"Breathing Techniques\",\n",
    "\"Deep Neural Networks\",\n",
    "\"Dietary Treatment\",\n",
    "\"Nature-Based Interventions\",\n",
    "\"Affective Computing\",\n",
    "\"Optimization Algorithms\",\n",
    "\"Play Therapy\",\n",
    "\"Generative Artificial Intelligence\",\n",
    "\"Optimization Algorithms\",\n",
    "\"Equine Assisted Therapy\",\n",
    "\"Equine Assisted Therapy\",\n",
    "\"Oxygen Therapy\",\n",
    "\"Post-COVID-19 Conditions\",\n",
    "\"Artificial Intelligence Ethics\",\n",
    "\"Computer Vision\",\n",
    "\"Mentalization-Based Interventions\",\n",
    "\"Metacognitive Therapy\",\n",
    "\"Mindfulness-Based Cognitive Therapy\",\n",
    "\"Intelligent Agents\",\n",
    "\"Deep Neural Networks\",\n",
    "\"Bayesian Algorithms\",\n",
    "\"Brain Computer Interface\",\n",
    "\"Digital Piracy\",\n",
    "\"Optimization Algorithms\",\n",
    "\"Positive Behavior Support\",\n",
    "\"Positive Psychology Therapy\",\n",
    "\"Post-COVID-19 Conditions\",\n",
    "\"Predictive Analysis\",\n",
    "\"Progressive Relaxation Therapy\",\n",
    "\"Feedback\",\n",
    "\"Decision Tree Algorithms\",\n",
    "\"Recommender Systems\",\n",
    "\"Experimental Ethics\",\n",
    "\"Research Quality\",\n",
    "\"Computer Assisted Surgery\",\n",
    "\"Biased Sampling\",\n",
    "\"Sensor Technology\",\n",
    "\"Artificial Neural Networks\",\n",
    "\"Social Prescribing\",\n",
    "\"Automated Speech Recognition\",\n",
    "\"Automated Speech Recognition\",\n",
    "\"Support Vector Machine Algorithms\",\n",
    "\"Synthetic Speech\",\n",
    "\"Exercise Therapy\",\n",
    "\"Noninvasive Brain Stimulation\"\n",
    "}\n",
    "\n",
    "# an empty dict to fill with the rows for the csv:\n",
    "new_terms_list = []\n",
    "new_synonyms_list = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert APA XML to SKOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms inkl. Synonyme: 10409\n",
      "Davon echte Concepts: 6949\n",
      "Neue Concepts: 76\n"
     ]
    }
   ],
   "source": [
    "# set element tree\n",
    "\n",
    "\n",
    "from rdflib import DCTERMS\n",
    "\n",
    "\n",
    "root = ET.parse(\"/home/tina/Developement/zpid-vocabularies/psyndex-terms/2023-06-Summer.xml\") # apa thesaurus file name goes here\n",
    "\n",
    "\n",
    "language_tag = \"en\"\n",
    "apa_thesaurus = Graph()\n",
    "apa_thesaurus.bind(\"terms\", TERMS) \n",
    "\n",
    "# Create a scheme by making a node in the graph and giving it an rdf:type skos:ConceptScheme:\n",
    "apa_scheme = URIRef(TERMS)\n",
    "apa_thesaurus.add((apa_scheme, RDF.type, SKOS.ConceptScheme))\n",
    "apa_thesaurus.add((apa_scheme, DCTERMS.created, Literal(\"1973-01-01\", datatype=XSD.date)))\n",
    "apa_thesaurus.add((apa_scheme, DCTERMS.creator, Literal(\"APA\")))\n",
    "apa_thesaurus.add((apa_scheme, DCTERMS.description, Literal(\"Subjects for describing psychological topics and areas of research.\")))\n",
    "thesaurus_name = \"Thesaurus of Psychological Index Terms\"\n",
    "apa_thesaurus.add((apa_scheme, DCTERMS.title, Literal(thesaurus_name, lang=language_tag)))\n",
    "apa_thesaurus.add((apa_scheme, SKOS.prefLabel, Literal(thesaurus_name, lang=language_tag)))\n",
    "apa_thesaurus.add((apa_scheme, DCTERMS.description, Literal(\"Subjects for describing psychological topics and areas of research.\")))\n",
    "# read today's date from the system and add it as dct:modified:\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "today_string = today.strftime(\"%Y-%m-%d\")\n",
    "apa_thesaurus.add((apa_scheme, DCTERMS.modified, Literal(today_string, datatype=XSD.date)))\n",
    "\n",
    "# To see the source xml's structure, uncomment this function:\n",
    "# def print_element(element, depth=0):\n",
    "#     print(\"\\t\"*depth, element.tag, element.attrib, element.text)\n",
    "#     for child in element:\n",
    "#         print_element(child, depth+1)\n",
    "\n",
    "\n",
    "# for child in root:\n",
    "# for child in root.getroot():\n",
    "#     # print_element(child)\n",
    "#     term_count += 1\n",
    "#     print(child.tag, child.attrib, child.text)\n",
    "# print(root.getroot().tag, root.getroot().attrib, root.getroot().text)\n",
    "\n",
    "# set root element for thesaurus. It is called \"TermList\" in the APA thesaurus\n",
    "term_list = root.find(\"TermList\")\n",
    "# print(term_list.tag, term_list.attrib, term_list.text)\n",
    "\n",
    "term_count = 0\n",
    "concept_count = 0\n",
    "\n",
    "\n",
    "# do this for every MainTerm in the thesaurus, but skip the ones that have a Use tag in their RelationsList:\n",
    "for term in term_list:\n",
    "# for term in term_list[0:7]:\n",
    "    term_count += 1\n",
    "\n",
    "    # make every term a concept by default - only if we find a USE tag later\n",
    "    # do we set this to false. Finally, we add only those terms as concepts to the \n",
    "    # graph that are true.\n",
    "    is_concept = True\n",
    "    pref_label = None\n",
    "    skos_notation = None\n",
    "    scope_note = None\n",
    "    history_note = None\n",
    "    # make empty Sets for skos:related, skos:narrower, and skos:broader terms:\n",
    "    # set because I don't want or need duplicates that may be in the data.\n",
    "    related_terms = []\n",
    "    broader_terms = []\n",
    "    narrower_terms = []\n",
    "    # and one for all altLabels:\n",
    "    alt_labels = []\n",
    "\n",
    "    \n",
    "    #print(term.tag, term.attrib, term.text)\n",
    "    pref_label = term.attrib[\"Subject\"]\n",
    "    skos_notation = term.attrib[\"Code\"]\n",
    "    dc_created_date = term.attrib[\"Introduced\"]\n",
    "    # go through all subelements of NotationList, if that exists, \n",
    "    # to find the one named \"ScopeNote\" and print its text:\n",
    "    for subelement in term:\n",
    "        if subelement.tag == \"NotationList\":\n",
    "            for relation in subelement:\n",
    "                if relation.tag == \"ScopeNote\":\n",
    "                    scope_note = relation.text\n",
    "                if relation.tag == \"HistoricalNote\":\n",
    "                    history_note = relation.text\n",
    "        if subelement.tag == \"RelationList\":\n",
    "            for relation in subelement:\n",
    "                if relation.tag == \"RelatedTerm\":\n",
    "                    # add the related thing to the set broader_terms_set:\n",
    "                    related_terms.append(relation.attrib[\"Code\"])\n",
    "                if relation.tag == \"BroaderTerm\":\n",
    "                    broader_terms.append(relation.attrib[\"Code\"])\n",
    "                if relation.tag == \"NarrowerTerm\":\n",
    "                    narrower_terms.append(relation.attrib[\"Code\"])\n",
    "                if relation.tag == \"UsedFor\":\n",
    "                    # this is the altLabel, then:\n",
    "                    alt_labels.append(relation.attrib[\"Subject\"])\n",
    "                if relation.tag == \"Use\":\n",
    "                    is_concept = False # meaning it is just a label, not a concept\n",
    "                    # we might export this as either a deprectated term or a skosxl:Label with \n",
    "                    # the text as skosxl:literalForm.\n",
    "                    #print(\"Use: \"+ relation.attrib[\"Code\"])\n",
    "    if is_concept:\n",
    "        concept_count += 1\n",
    "        # add a new element to the list for the csv table of newly added terms\n",
    "        if pref_label in new_concepts:\n",
    "            alt_labels_concatenated = \"\"\n",
    "            for label in alt_labels:\n",
    "                alt_labels_concatenated = label + \"; \"\n",
    "            new_terms_list.append({\"Code\": skos_notation, \"CT Englisch\": pref_label, \"Synonyme Englisch\": alt_labels_concatenated, \"CT Deutsch\": None, \"Synonyme Deutsch\": None, \"Scopenote\": scope_note, \"Historynote\": history_note, \"Indikatoren\": None}) \n",
    "        \n",
    "        # make a node in the graph for the concept with a URI built from \n",
    "        # \"https://w3id.org/zpid/vocabs/terms/\" + \"Code\"\n",
    "        # concept_uri = \"https://w3id.org/zpid/vocabs/terms/\" + skos_notation\n",
    "        concept_uri = TERMS[skos_notation]\n",
    "        apa_thesaurus.add((concept_uri, RDF.type, SKOS.Concept))\n",
    "        # add it to the scheme:\n",
    "        apa_thesaurus.add((concept_uri, SKOS.inScheme, apa_scheme ))\n",
    "        # then add the properties to it:\n",
    "        ## first, the prefLabel \n",
    "        apa_thesaurus.add((concept_uri, SKOS.prefLabel, Literal(pref_label, lang=language_tag)))\n",
    "        ## the notation:\n",
    "        apa_thesaurus.add((concept_uri, SKOS.notation, Literal(skos_notation)))\n",
    "        ## add the date of creation:\n",
    "        apa_thesaurus.add((concept_uri, DCTERMS.created, Literal((dc_created_date+\"-01-01\"), datatype=XSD.date)))\n",
    "\n",
    "        ## then, any altLabels:\n",
    "        for label in alt_labels:\n",
    "            apa_thesaurus.add((concept_uri, SKOS.altLabel, Literal(label, lang=language_tag)))\n",
    "            # is it a new altLabel?\n",
    "            if label in new_altlabels:\n",
    "                print(label)\n",
    "                # new_synonyms_list.append({\"Neues Synonym\": label, \"Ist Synonym für postable Term\": pref_label, \"Code des postable Terms\": skos_notation, \"Scopenote\": scope_note, \"Historynote\": history_note})\n",
    "\n",
    "        # the scope_note and history_note:\n",
    "        if scope_note is not None:\n",
    "            apa_thesaurus.add((concept_uri, SKOS.scopeNote, Literal(scope_note, lang=language_tag)))\n",
    "        if history_note is not None:\n",
    "            apa_thesaurus.add((concept_uri, SKOS.historyNote, Literal(history_note, lang=language_tag)))\n",
    "\n",
    "        for term in related_terms:\n",
    "            apa_thesaurus.add((concept_uri, SKOS.related, URIRef(TERMS[term])))\n",
    "\n",
    "        for term in broader_terms:\n",
    "            apa_thesaurus.add((concept_uri, SKOS.broader, URIRef(TERMS[term])))\n",
    "\n",
    "        for term in narrower_terms:\n",
    "            apa_thesaurus.add((concept_uri, SKOS.narrower, URIRef(TERMS[term])))\n",
    "    # if it is not a concept, it is only a synonym:\n",
    "    else:\n",
    "        # add it as a skosxl:Label to the graph?\n",
    "        pass\n",
    "\n",
    "               \n",
    "apa_thesaurus.serialize(\"apa_thes.ttl\", format=\"turtle\")\n",
    "print(\"Terms inkl. Synonyme: \" + str(term_count))\n",
    "print(\"Davon echte Concepts: \" + str(concept_count))\n",
    "print(\"Neue Concepts: \" + str(len(new_concepts)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the result through skosify:\n",
    "# skosify -c skosify.cfg apa_thes.ttl -o apa_thes_skosified.ttl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Make helper files for manually translating newly added terms\n",
    "\n",
    "Above, we added the list of new postable terms from the supporting document the APA sends into the variable new_terms_list.\n",
    "In the loop through each concept, while writing the RDF nodes, we also filled a list with dicts that hold the information for each new term. We can use this list to create a table for Google Drive that psychologists can use to fill with German translations of the new terms. (We can then use this table to create a new SKOS file with the German translations.)\n",
    "\n",
    "We make the table as a csv that can be imported into google sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. load the thesaurus file (could do this without rdf, too)\n",
    "# 2. identify the uri of the new concepts from the new concept preflabels in new_concepts\n",
    "# 3. get preflabel and scopenote and write into a csv file\n",
    "# 4. identify the uri of the concept of each new synonym in new_altlabels\n",
    "# 5. do the same as for 3  \n",
    "\n",
    "with open('new_terms.csv', 'w', newline='') as csvfile:\n",
    "    # termstable = csv.writer(csvfile, delimiter=' ',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    termstable = csv.writer(csvfile, delimiter=' ')\n",
    "    fieldnames = ['Code','CT Englisch','Synonyme Englisch','CT Deutsch','Synonyme Deutsch', 'Scopenote', 'Historynote','Indikatoren']\n",
    "    termstable = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    termstable.writeheader()\n",
    "    for term in new_terms_list:\n",
    "        termstable.writerow(term)\n",
    "\n",
    "with open('new_synonyms.csv', 'w', newline='') as csvfile:\n",
    "    # termstable = csv.writer(csvfile, delimiter=' ',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    synonymstable = csv.writer(csvfile, delimiter=' ')\n",
    "    fieldnames = ['Neues Synonym','Ist Synonym für postable Term','Code des postable Terms','Scopenote','Historynote']\n",
    "    synonymstable = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    synonymstable.writeheader()\n",
    "    for term in new_synonyms_list:\n",
    "        synonymstable.writerow(term)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Get German translations from STAR as XML\n",
    "## 4. Convert STAR XML to SKOS (labels only)\n",
    "## 5. Merge SKOS files, clean up with skosify"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.10.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
