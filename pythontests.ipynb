{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n"
     ]
    }
   ],
   "source": [
    "import langid\n",
    "langid.set_languages([\"de\", \"en\"])\n",
    "\n",
    "def guess_language(string_in_language):\n",
    "    return (langid.classify(string_in_language)[0])\n",
    "\n",
    "# print(langid.classify(\"Zur transgenerationalen Traumatisierung\"))\n",
    "# print(langid.classify(\"Ätiologie und Ansätze für die Therapie\"))\n",
    "\n",
    "# print(langid.classify(\"Zur transgenerationalen Traumatisierung\")[0])\n",
    "print(guess_language(\"\\\"A 'true' artist may draw mountainous seas!\\\" - Eine Würdigung von Paul Watzlawick zu seinem 100. Geburtstag\"))\n",
    "# print(guess_language(\"What does it mean for children's development whether and to what extent both parents are employed and they accordingly spend part of the day outside the family? And how should care for young children be structured? Research findings from Developmental Psychology provide some answers. (translated by DeepL)\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking strings for non-letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "language = \"EnglishX$X$\"\n",
    "# check if string contains any non-letter character:\n",
    "if not language.isalpha():\n",
    "    print(\"yes\")\n",
    "else:\n",
    "    print(\"no\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconciling affiliation with ror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zagreb Childrenğt;'s Hospital, Pediatric Clinic\n",
      "Test Zagreb Childrenğt;'s Hospital, Pediatric Clinic more\n",
      "p &lt; .05\n",
      " &lt; \n",
      "haha ∞ ™\n",
      "Geoffrey Jefferson\n"
     ]
    }
   ],
   "source": [
    "import requests_cache\n",
    "from datetime import timedelta\n",
    "# from mappings import geonames_countries\n",
    "# from mappings import abstract_origins\n",
    "# from mappings import dd_codes\n",
    "\n",
    "# for reconciling affiliation strings with ror api:\n",
    "ROR_API_URL = \"https://api.ror.org/organizations?affiliation=\"\n",
    "\n",
    "# for getting data about a known id:\n",
    "ROR_API_LOOKUP_URL = \"https://api.ror.org/organizations/\"\n",
    "\n",
    "from mappings import dd_codes\n",
    "\n",
    "def replace_encodings(text):\n",
    "    for case in dd_codes:\n",
    "        text = text.replace(case[0], case[1]) \n",
    "    return text\n",
    "\n",
    "urls_expire_after = {\n",
    "    # Custom cache duration per url, 0 means \"don't cache\"\n",
    "    # f'{SKOSMOS_URL}/rest/v1/label?uri=https%3A//w3id.org/zpid/vocabs/terms/09183&lang=de': 0,\n",
    "    # f'{SKOSMOS_URL}/rest/v1/label?uri=https%3A//w3id.org/zpid/vocabs/terms/': 0,\n",
    "}\n",
    "\n",
    "session = requests_cache.CachedSession(\n",
    "    \".cache/requests\",\n",
    "    allowable_codes=[200, 404],\n",
    "    expire_after=timedelta(days=30),\n",
    "    urls_expire_after=urls_expire_after,\n",
    ")\n",
    "\n",
    "def get_ror_id_from_api(affiliation_string):\n",
    "    # this function takes a string with an affiliation name and returns the ror id for that affiliation from the ror api\n",
    "    # clean the string to make sure things like \"^DDS\" are replaced:\n",
    "    affiliation_string = replace_encodings(affiliation_string)\n",
    "    #replace_encodings(affiliation_string)\n",
    "    ror_api_url = ROR_API_URL + affiliation_string\n",
    "    # make a request to the ror api:\n",
    "    # ror_api_request = requests.get(ror_api_url)\n",
    "    # make request to api with caching:\n",
    "    ror_api_request = session.get(\n",
    "            ror_api_url, timeout=20\n",
    "    )\n",
    "    # if the request was successful, get the json response:\n",
    "    if ror_api_request.status_code == 200:\n",
    "        ror_api_response = ror_api_request.json()\n",
    "        # check if the response has any hits:\n",
    "        if len(ror_api_response[\"items\"]) > 0:\n",
    "            # if so, get the item with a key value pair of \"chosen\" and \"true\" and return its id:\n",
    "            for item in ror_api_response[\"items\"]:\n",
    "                if item[\"chosen\"] == True:\n",
    "                    return item[\"organization\"][\"id\"]\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "    # here is a list of affiliation strings to go through:\n",
    "affiliation_strings = [\n",
    "    \"Klinik für Frauenheilkunde und Geburtshilfe, Universitätsklinikum Ulm\",\n",
    "    \"Klinik für Psychososmatische Medizin und Psychotherapie, Universitätsklinikum Ulm\",\n",
    "    \"Sektion Medizinische Psychologie, Universitätsklinikum Ulm\",\n",
    "    \"Klinik für Psychososmatische Medizin und Psychotherapie, Universitätsklinikum Ulm\",\n",
    "    \"Psychology School, Hochschule Fresenius ^DDS University of Applied Sciences, Düsseldorf\",\n",
    "    \"Fakultät Medizin, MSH Medical School Hamburg ^DDS University of Applied Sciences and Medical University, Hamburg\",\n",
    "    \"Fakultät Medizin, MSH Medical School Hamburg ^DDS University of Applied Sciences and Medical University, Hamburg\",\n",
    "    \"Department of Child and Adolescent Psychiatry, Psychosomatics and Psychotherapy; LVR Klinikum Essen; University Hospital Essen; University of Duisburg-Essen; Essen\",\n",
    "    \"Child and Adolescent Psychiatry/Psychology, Erasmus Medical Center Rotterdam\"\n",
    "]\n",
    "\n",
    "# use the function to get the ror id for each affiliation string:\n",
    "\n",
    "# for affiliation_string in affiliation_strings:\n",
    "#     print(replace_encodings(affiliation_string) + \": \" + str(get_ror_id_from_api(affiliation_string)))\n",
    "\n",
    "# print(replace_encodings(\"Stimulus ^DDS non psychological interference ^DDL analogy\"))\n",
    "print(replace_encodings(\"Zagreb Children^D&gt;'s Hospital, Pediatric Clinic\"))\n",
    "print(\"Test \" + replace_encodings(\"Zagreb Children^D&gt;'s Hospital, Pediatric Clinic\") + \" more\")\n",
    "print(replace_encodings(\"p &lt; .05\"))\n",
    "print(replace_encodings(' &lt; '))\n",
    "print(replace_encodings('haha ^DIF ^DTM'))\n",
    "print(replace_encodings('Geo^Dffrey Je^Dfferson'))\n",
    "# print(get_ror_id_from_api(\"Klinik für Frauenheilkunde und Geburtshilfe, Universitätsklinikum Ulm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "def utf8len(s):\n",
    "    return len(s.encode('utf-8'))\n",
    "\n",
    "print(utf8len(\"Test string\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated: Reconcile with Wikidata\n",
    "\n",
    "The \"reconciler\" package can use other reconciliation APIs, too. Wikidata is the default. \n",
    "To change the API endpoint, call the reconcile() function with the parameter `reconciliation_endpoint=\"https...\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 6052.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from reconciler import reconcile\n",
    "import pandas as pd\n",
    "\n",
    "# A DataFrame with a column you want to reconcile.\n",
    "test_df = pd.DataFrame(\n",
    "    {\n",
    "        \"City\": [\"Rio de Janeiro\", \"São Paulo\", \"São Paulo\", \"Natal\"],\n",
    "        \"Country\": [\"Q155\", \"Q155\", \"Q155\", \"Q155\"],\n",
    "        \"Land\": [\"XD-BR\", \"XD-BR\", \"XD-BR\", \"XD-BR\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Reconcile against type city (Q515), getting the best match for each item.\n",
    "reconciled = reconcile(test_df[\"City\"], type_id=\"TerritorialCorporateBodyOrAdministrativeUnit\", property_mapping={\"geographicAreaCode\": test_df[\"Land\"]}, reconciliation_endpoint=\"https://lobid.org/gnd/reconcile/\")\n",
    "# reconciled = reconcile(test_df[\"City\"], type_id=\"Q515\")\n",
    "\n",
    "# save the results to a csv file:\n",
    "test_df.to_csv(\"test.csv\")\n",
    "reconciled.to_csv(\"reconciled.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4815.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# testing with some of our terms and GND Subject Headings:\n",
    "test_df = pd.DataFrame(\n",
    "     {\n",
    "         \"TermE\": [\"Inductive Deductive Reasoning\", \"Spatial Imagery\", \"Verbal Comprehension\"],\n",
    "         \"TermD\": [\"Induktiv-deduktives logisches Denken\", \"Räumliche Bildvorstellung\", \"Verbales Verständnis\"],\n",
    "     }\n",
    "    )\n",
    "\n",
    "reconciled = reconcile(test_df[\"TermE\"], type_id=\"SubjectHeading\", reconciliation_endpoint=\"https://lobid.org/gnd/reconcile/\")\n",
    "\n",
    "# save the results to a csv file:\n",
    "test_df.to_csv(\"test_terms.csv\")\n",
    "reconciled.to_csv(\"reconciled_terms.csv\")\n",
    "\n",
    "# This is not going to work, our cts just have too different wording compared to their gnd subject headings!\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use our authority records for insitutes to reconcile affiliations\n",
    "\n",
    "At first, I thought it was a good idea to do this by exposing our csv files as reconc apis using this JAVA tool: https://okfnlabs.org/reconcile-csv/\n",
    "\n",
    "It gives us a reconciliation API endpoint (on http://localhost:8000/reconcile) that one could use with the \"reconciler\" package, like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 6615.62it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame(\n",
    "     {\n",
    "         \"Obstname\": [\"Äpfel\", \"Birne\", \"Himbeere\"],\n",
    "     }\n",
    "    )\n",
    "\n",
    "reconciled = reconcile(test_df[\"Obstname\"], reconciliation_endpoint=\"http://localhost:8000/reconcile\")\n",
    "reconciled.to_csv(\"reconciled_fruit.csv\")  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above works, but we need to select which part to add to the record. It returns the label that was matched, a score, a match True/False (only True if score 1.0! Maybe we can lower the cutoff to 0.75?), and a type \n",
    "\n",
    "Also, this only works with dataframes, so whole tables, whereas we want to reconcile individual strings.\n",
    "\n",
    "Idea: \n",
    "Instead of reconciling with the API, we can just import the CSV of the authority institutes (as a list of dicts) and use fuzzywuzzy to match a given affiliation string. \n",
    "[Fuzzywuzzy](https://pypi.org/project/fuzzywuzzy/) (\"Fuzzy string matching in python\") compares two strings and returns a score. We can use a cutoff of 75% to decide if the string matches the label.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import our authority institutes as CSV, use fuzzywuzzy to match a given affiliation string to them\n",
    "\n",
    "Fuzzywuzzy, if passed a list with sublists for synonyms, also automatically looks in there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Am besten passt: 79702f56-c49f-4951-bd4b-d1939e52dd46\n",
      "Am besten passt: c22de612-48f9-4952-9bda-51cea5c88785\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import csv\n",
    "\n",
    "# import csv file with dachlux institutes:\n",
    "with open('institute_lux.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    # save it in a list:\n",
    "    dachlux_institutes = list(reader)\n",
    "    # split string \"known_names\" into a list of strings on \"##\":\n",
    "    for institute in dachlux_institutes:\n",
    "        institute[\"known_names\"] = institute[\"known_names\"].split(\" ## \")\n",
    "# print(\"Und die ganze Tabelle:\")\n",
    "# print(dachlux_institutes)\n",
    "\n",
    "\n",
    "# affiliation_string = \"Abteilung für Psychologie, University of Luxembourg, Esch-sur-Alzette\"\n",
    "# expected match: uuid: bfe28ac0-4901-4125-aaa6-c1fb6c644b7a, Centre de Prévention des Toxicomanies (CePT)\n",
    "\n",
    "def match_local_authority_institutes(string, list):\n",
    "    # this function takes a string and returns the best match from a list of strings\n",
    "    # first, get the list of strings:\n",
    "    # then, get the best match (token_set_ratio seems to be the best scorer for our purposes, so we use that):)):\n",
    "    # It yields 100% for exact matches. It is also insensitive to word order differences.\n",
    "    best_match = process.extractOne(string, list, scorer=fuzz.token_set_ratio)\n",
    "    # return best_match\n",
    "    # or if i just wanted the value in \"uuid\":\n",
    "    return best_match[0].get(\"uuid\")\n",
    "\n",
    "print(\"Am besten passt:\",match_local_authority_institutes(\"Fakultät für Geisteswissenschaften, Erziehungswissenschaften und Sozialwissenschaften; Universität Luxemburg\", dachlux_institutes))\n",
    "print(\"Am besten passt:\",match_local_authority_institutes(\"Department of Behavioral and Cognitive Sciences, University of Luxembourg, Esch-sur-Alzette\", dachlux_institutes))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this in the script, we need the following pseudo-code:\n",
    "\n",
    "- check if the affiliation string contains a country name\n",
    "- if yes, check if the country name is in the list of countries (D, A, CH, LUX)\n",
    "- only then use fuzzywuzzy to match the affiliation string to the list of institutes for that country\n",
    "\n",
    "If we have separate csv files for each country, we can use the country name to select the right file.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a ror id that we have to look up more data\n",
    "\n",
    "For authority records, we can use the ror id (that we already looked up using the api with the affiliation parameter) to look up more data about the institute, like the country, the name, the aliases, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Centre for European Economic Research', 'ZEW', 'Mannheim', 2873891, 'DE', 'Germany', {'ISNI': {'preferred': None, 'all': ['0000 0004 0492 4665']}, 'Wikidata': {'preferred': None, 'all': ['Q191206']}, 'GRID': {'preferred': 'grid.13414.33', 'all': 'grid.13414.33'}})\n"
     ]
    }
   ],
   "source": [
    "# https://api.ror.org/organizations/00tjv0s33\n",
    "\n",
    "# for getting data about a known id:\n",
    "from tkinter import N\n",
    "\n",
    "\n",
    "ROR_API_LOOKUP_URL = \"https://api.ror.org/organizations/\"\n",
    "\n",
    "# For research institutes/departments, it makes sense to use ror-id for things that are true for the parent \n",
    "# organization as well as for the department: country code, the country name, the city. \n",
    "\n",
    "# Trouble is: we have no way to know if a reconciled ror-id is for a department or for its parent organization.\n",
    "# if sb used their university as the affiliation, we would get the ror-id for the university, \n",
    "# but if sb has a department, we still get the ror-id for the university, and we can't say: \n",
    "# this is the ror-id for the parent or for this exact suborg. Maybe! There is a way to find out: \n",
    "# if it's a full match (not partial) then it is a \"sameAs\" relationship,\n",
    "# if it's only a partial match to the org name, it's a \"related\" or \"Child\" relationship?.\n",
    "\n",
    "# The response is a JSON object containing a full ROR record. \n",
    "# See [ROR data structure](https://ror.readme.io/docs/ror-data-structure) for details about the fields and values in a ROR record.\n",
    "# we are interested in:\n",
    "# acryonyms (list)\n",
    "# aliases (list)\n",
    "# country.country_code (string), country.country_name (string)\n",
    "# addresses[0].city (string), \n",
    "# addresses[0].country_geonames_id -> can link to our own geographica's\n",
    "# addresses[0].geonames_city.id (string), maybe: addresses[0].geonames_city.name (string)\n",
    "# Allowed external IDs: Crossref Funder ID (FundRef), ISNI, Wikidata. Other external IDs not actively curated include GRID, OrgRef, HESA, UCAS, UKPRN, CNRS.\n",
    "# external_ids.ISNI.preferred (string), or if \"null\": .external_ids.ISNI.all (array, or just use the first [0])\n",
    "# external_ids.Wikidata.preferred (string), or if \"null\": .external_ids.Wikidata.all (array, or just use the first [0])\n",
    "# relationships (array) mit jeweils:\n",
    "#    .id (ror-id mit http-Vorspann der related org)\n",
    "#    .type (string, eins von \"Related\", \"Successor\",\"Predecessor\", \"Parent\", \"Child\")\n",
    "#    .label (string, z.B. \"Leibniz-Association\")\n",
    "# we also want the German name or name in other languages, if available. \n",
    "# it should be in .labels : labels[0].iso639 = \"de\", labels[0].label = \"Leibniz-Gemeinschaft\"\n",
    "# and we can construct a langstring from it like \"Leibniz-Gemeinschaft\"@de\n",
    "\n",
    "\n",
    "def get_ror_authority_data(ror_id):\n",
    "    ror_api_url = ROR_API_LOOKUP_URL + ror_id\n",
    "    # make a request to the ror api:\n",
    "    # ror_api_request = requests.get(ror_api_url)\n",
    "    # make request to api with caching:\n",
    "    ror_api_request = session.get(\n",
    "            ror_api_url, timeout=20\n",
    "    )\n",
    "    # if the request was successful, get the json response:\n",
    "    if ror_api_request.status_code == 200:\n",
    "        ror_api_response = ror_api_request.json()\n",
    "        name = ror_api_response[\"name\"]\n",
    "        for acronym in ror_api_response[\"acronyms\"]:\n",
    "            if acronym is not None:\n",
    "                acronym = acronym\n",
    "            else:\n",
    "                acronym = None\n",
    "        city = ror_api_response[\"addresses\"][0][\"city\"]\n",
    "        geonames_city = ror_api_response[\"addresses\"][0][\"geonames_city\"][\"id\"]\n",
    "        country_code = ror_api_response[\"country\"][\"country_code\"]\n",
    "        country_name = ror_api_response[\"country\"][\"country_name\"]\n",
    "        external_ids = ror_api_response[\"external_ids\"]\n",
    "\n",
    "        return name,acronym, city, geonames_city, country_code, country_name, external_ids\n",
    "        # check if the response has any hits:\n",
    "        # if len(ror_api_response[\"items\"]) > 0:\n",
    "        #     # if so, get the item with a key value pair of \"chosen\" and \"true\" and return its id:\n",
    "        #     for item in ror_api_response[\"items\"]:\n",
    "        #         if item[\"chosen\"] == True:\n",
    "        #             return item[\"organization\"][\"id\"]\n",
    "        # else:\n",
    "        #     return None\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "# print(get_ror_authority_data(\"0165gz615\")) # ZPID\n",
    "print(get_ror_authority_data(\"02qnsw591\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feld GRANT migrieren\n",
    "\n",
    "- Vor allem Unterfeld |n - auftrennen! |i aufheben, und wenn möglich überflüssiges, was keine Nummer ist, wegwerfen.\n",
    "\n",
    "\n",
    "Ergebnis soll so aussehen (ähnlich wie bei Crossref:, aber mit grant_name ähnoich DataCite, dort heißt es aber grantTitle ) :\n",
    "\n",
    "```\n",
    "{\n",
    "    'funder': \n",
    "    {\n",
    "        'funder_name': 'Sächsische Aufbaubank ^DDS Förder bank ^DDS (SAB)', 'funder_id': None\n",
    "    }, \n",
    "        'grants': \n",
    "        [\n",
    "            {\n",
    "                'grant_number': '100362999 an YG', \n",
    "                'grant_name': None\n",
    "            }\n",
    "        ], \n",
    "        'funding_note': None\n",
    "},\n",
    "{'funder': {'funder_name': 'Institute for Applied Research, Development and Further Education (IAF) at the Catholic University of Applied Sciences in Freiburg', 'funder_id': None}, 'grants': None, 'funding_note': None},\n",
    "{\n",
    "    'funder': \n",
    "    {\n",
    "        'funder_name': 'JSPS KAKENHI', \n",
    "        'funder_id': None\n",
    "    }, \n",
    "    'grants': [\n",
    "        {\n",
    "            'grant_number': '15K00871', \n",
    "            'grant_name': None\n",
    "        }, \n",
    "        {\n",
    "            'grant_number': '18KK0055', \n",
    "            'grant_name': None\n",
    "        }\n",
    "    ], \n",
    "    'funding_note': None}\n",
    "```\n",
    "\n",
    "Note: may remove the general \"funding_note\" field, anywhere else, or move its contents as grant_name to each grant (as OpenAlex does). May rename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'funder': {'funder_name': 'Austrian Science Fund (FWF)', 'funder_id': None}, 'grants': None, 'funding_note': 'Open access funding'}\n"
     ]
    }
   ],
   "source": [
    "n_strings = (\"KND1: 01GI0102, 01GI0420, 01GI0422, 01GI0423, 01GI0429, 01GI0431, 01GI0433, 01GI0434; KNDD: 01GI0710, 01GI0711, 01GI0712, 01GI0713, 01GI0714, 01GI0715, 01GI0716\",\n",
    "             \"HO5852/1-1\",\"392443797\",\"01GI1008C\",\"801210010-20\",\n",
    "             \"TA 857/3-2\", \"2016YFC1306800\", \"81671329\", \"18ZDA293\", \"17411969900\",\n",
    "             \"20144Y0053\", \"SHDC12014111\", \"13dz2260500\", \"ZH2018QNB19\",\n",
    "             \"2018-FX-04, 2013-YJGJ-03\", \"IIR-1303\", \n",
    "             \"01GL1714A; 01GL1714B; 01GL1714C; 01GL1714D, 01GY1613\",\n",
    "             \"15K00871 and 18KK0055\", \"366/14\", \"386/14\", \"100362999 an YG\"\n",
    "             )\n",
    "\n",
    "\n",
    "def extract_grant_numbers(subfield_n_string):\n",
    "    # this function takes a string and returns a list of award numbers\n",
    "    # first, split the string on \",\" or \";\" or \"and\": (first replacing all semicolons and \"ands\" with commas)\")\n",
    "    subfield_n_string = subfield_n_string.replace(\" and \", \", \")\n",
    "    subfield_n_string = subfield_n_string.replace(\";\", \",\")\n",
    "    subfield_n_string = subfield_n_string.split(\", \")\n",
    "    # in each of the returned list elements, remove any substrings that are shorter \n",
    "    # than 5 characters (to get rid of things like \" for\" or \"KDL: \" YG: \" etc.)\n",
    "    # for element in subfield_n_string:\n",
    "    #     if len(element) < 5:\n",
    "    #         subfield_n_string.remove(element)\n",
    "    # go through all the list elements and replace each with a dict,\n",
    "    # which has a key \"grant_number\" and a key \"grant_name\" (which is None for now):\n",
    "    for i, element in enumerate(subfield_n_string):\n",
    "        subfield_n_string[i] = {\"grant_number\": element, \"grant_name\": None}\n",
    "    # return the list of dicts:\n",
    "    return subfield_n_string\n",
    "\n",
    "# extract_grant_numbers(n_strings[0])\n",
    "\n",
    "\n",
    "\n",
    "def build_grant_from_starfield(grantfield):\n",
    "    # this function takes a string and returns a funder, grant number, grant name, grant holder\n",
    "    # first, use anything before the first \"|\" as the funder:\n",
    "    funder = {\"funder_name\": grantfield.split(\"|\")[0].strip(), \"funder_id\": None}\n",
    "    # then check the rest for a grant number:\n",
    "    if \"|n \" in grantfield:\n",
    "        grants = grantfield.split(\"|n \")[1].split(\" |\")[0]\n",
    "        grants = extract_grant_numbers(grants)\n",
    "    else:\n",
    "        grants = None\n",
    "    # then check the rest for a grant name:\n",
    "    if \"|i \" in grantfield:\n",
    "        funding_info = grantfield.split(\"|i \")[1]\n",
    "    else:\n",
    "        funding_info = None\n",
    "    # return a dict of the variables:\n",
    "    return {\"funder\": funder, \"grants\": grants, \"funding_note\": funding_info}\n",
    "\n",
    "GRANTs = (\n",
    "\"Sächsische Aufbaubank ^DDS Förder bank ^DDS (SAB) |n 100362999 an YG |e Golub, Yulia\", \n",
    "\"German Federal Ministry of Education and Research |n KND: 01GI0102, 01GI0420, 01GI0422, 01GI0423, 01GI0429, 01GI0431, 01GI0433, 01GI0434; KNDD: 01GI0710, 01GI0711, 01GI0712, 01GI0713, 01GI0714, 01GI0715, 01GI0716\",\n",
    "'\"German Federal Ministry of Education and Research |n 01GL1714A; 01GL1714B; 01GL1714C; 01GL1714D, 01GY1613 |i AgeDifferent.de: Funding program \"Gesund^DDL ein Leben lang\"',\n",
    "\"Austrian Science Fund (FWF) |i Open access funding\",\n",
    "\"JSPS KAKENHI |n 15K00871 and 18KK0055\",\n",
    "\"Institute for Applied Research, Development and Further Education (IAF) at the Catholic University of Applied Sciences in Freiburg |e Eric Pfeifer\",\n",
    ")\n",
    "\n",
    "print(build_grant_from_starfield(GRANTs[3]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.10.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
